Docker Images:

Toolbox: lhu98jes/big-data-processing-toolbox

Hadoop: - namenode: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
		- datanode: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8

Spark: bitnami/spark

Jupyter Notebook: lhu98jes/proj-jupyter

Sonarqube: lhu98jes/proj-sonarqube-scanner

docker pull lhu98jes/big-data-processing-toolbox
docker tag lhu98jes/big-data-processing-toolbox gcr.io/caramel-aria-325416/lhu98jes/big-data-processing-toolbox

Docker Images Usage:

1. Build, push, and run docker image for controller

	docker build -f Dockerfile -t lhu98jes/big-data-processing-toolbox .
	docker push lhu98jes/big-data-processing-toolbox
	docker run -d -p 8000:8000 lhu98jes/big-data-processing-toolbox

2. Build, push and run docker image for jupyter notebook

	docker build -f Dockerfile -t lhu98jes/proj-jupyter .
	docker push lhu98jes/proj-jupyter
	docker run -p 8888:8888 lhu98jes/proj-jupyter

3. Build, push and run docker image for sonarqube

	docker build -f Dockerfile -t lhu98jes/proj-sonarqube-scanner .
	docker push lhu98jes/proj-sonarqube-scanner
	docker run -d -e SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true -p 9000:9000 lhu98jes/proj-sonarqube-scanner
	(login&password:admin; or login: admin, password: admin1)

4. Pull and run docker image for spark

	docker pull bitnami/spark
	docker run -d --name spark -e SPARK_MODE=master bitnami/spark

5. Pull and set up hadoop cluster with one master node and two worker nodes
	
	Go to Hadoop folder, and do "docker-compose up"

Reference:

	https://techexpert.tips/sonarqube/sonarqube-scanner-installation-ubuntu-linux/
	

Deployment:

1. kubectl create ns project

2. For Sonar, Spark, and Jupyter:

	kubectl apply -f sonar_deployment.yaml
	kubectl apply -f spark_deployment.yaml
	kubectl apply -f jupyter_notebook_deployment.yaml
	kubectl apply -f services_deployment.yaml

3. For Hadoop:
	
	Manually deploy namenode and datanode, following demo in class

4. Once have all the external IPs for all services, update in toolbox's code (views.py)

5. Push docker image for toolbox

6. Deploy toolbox:

	kubectl apply -f toolbox_deployment.yaml
	kubectl apply -f load_balancer_deployment.yaml

7. Once have the external IP for toolbox, we add this IP in settings.py, and then push it to Docker as lhu98jes/big-data-processing-toolbox:deploy

8. Pull the "deploy" version in GCP, and have the service point to the new version of toolbox image

